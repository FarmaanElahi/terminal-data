{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-08T08:19:50.418833Z",
     "start_time": "2025-02-08T08:19:50.003640Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "import requests\n",
    "import json\n",
    "from bs4 import BeautifulSoup\n"
   ],
   "id": "4fd528b344d4f2c",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-08T08:20:23.782369Z",
     "start_time": "2025-02-08T08:20:18.931947Z"
    }
   },
   "cell_type": "code",
   "source": "!pip install pyarrow",
   "id": "d7a3e0ebeda3792",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pyarrow\r\n",
      "  Downloading pyarrow-19.0.0-cp312-cp312-macosx_12_0_arm64.whl.metadata (3.3 kB)\r\n",
      "Downloading pyarrow-19.0.0-cp312-cp312-macosx_12_0_arm64.whl (30.7 MB)\r\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m30.7/30.7 MB\u001B[0m \u001B[31m14.3 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0ma \u001B[36m0:00:01\u001B[0m\r\n",
      "\u001B[?25hInstalling collected packages: pyarrow\r\n",
      "Successfully installed pyarrow-19.0.0\r\n"
     ]
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-08T09:02:27.984761Z",
     "start_time": "2025-02-08T09:02:27.978418Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def download_scanner_columns():\n",
    "    # URL of the webpage\n",
    "    url = 'https://shner-elmo.github.io/TradingView-Screener/fields/stocks.html'\n",
    "    response = requests.get(url)\n",
    "    response.raise_for_status()\n",
    "    soup = BeautifulSoup(response.text, 'html.parser')\n",
    "    table = soup.find('table')\n",
    "    # Initialize a list to store extracted data\n",
    "    columns = []\n",
    "    for row in table.tbody.find_all('tr'):\n",
    "        cells = row.find_all('td')\n",
    "        if len(cells) == 3:\n",
    "            # Extract common fields\n",
    "            display_name = cells[1].get_text(strip=True)\n",
    "            column_type = cells[2].get_text(strip=True)\n",
    "\n",
    "            # Check if the first cell contains <details>\n",
    "            details = cells[0].find('details')\n",
    "            if details:\n",
    "                # Extract each <li> inside <ul> as Column Name\n",
    "                column_names = [li.get_text(strip=True) for li in details.find_all('li')]\n",
    "            else:\n",
    "                # Otherwise, use the text inside <td> directly\n",
    "                column_names = [cells[0].get_text(strip=True)]\n",
    "\n",
    "            # Store extracted data\n",
    "            for column_name in column_names:\n",
    "                columns.append({\n",
    "                    'Column Name': column_name,\n",
    "                    'Display Name': display_name,\n",
    "                    'Type': column_type\n",
    "                })\n",
    "        else:\n",
    "            print(f\"Unexpected row format: {row}\")\n",
    "\n",
    "    pd.DataFrame(columns).to_parquet('../data/scanner/cols.parquet', compression='zstd')\n",
    "    print(\"Saved scanner column info\")\n",
    "    return columns\n"
   ],
   "id": "650f5d94f20c8b6f",
   "outputs": [],
   "execution_count": 35
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-08T09:02:30.020041Z",
     "start_time": "2025-02-08T09:02:30.016933Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def fetch_scanner_data(market: str, cols: list[str]):\n",
    "    url = f\"https://scanner.tradingview.com/{market}/scan\"\n",
    "    payload = {\n",
    "        \"columns\": cols,\n",
    "        \"filter\": [{\"left\": \"exchange\", \"operation\": \"in_range\", \"right\": [\"NSE\"]}],\n",
    "        \"ignore_unknown_fields\": False,\n",
    "        \"sort\": {\"sortBy\": \"market_cap_basic\", \"sortOrder\": \"desc\"},\n",
    "    }\n",
    "    headers = {'Content-Type': 'text/plain'}\n",
    "    r = requests.request(\"POST\", url, headers=headers, data=json.dumps(payload))\n",
    "    r.raise_for_status()\n",
    "    return r.json()['data']"
   ],
   "id": "f2499084a90c94de",
   "outputs": [],
   "execution_count": 36
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-08T09:02:30.487197Z",
     "start_time": "2025-02-08T09:02:30.483887Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def download_scanner_data(market: str, columns: list[list[str]]):\n",
    "    data: pd.DataFrame | None = None\n",
    "    for idx, cols in enumerate(columns):\n",
    "        symbols = fetch_scanner_data(market, cols)\n",
    "        print(f\"Loaded {((idx + 1) * 50)}\")\n",
    "        d = [[s['s']] + s['d'] for s in symbols]\n",
    "        df = pd.DataFrame(d, columns=['ticker'] + cols)\n",
    "        if data is None:\n",
    "            data = df\n",
    "        else:\n",
    "            data = pd.merge(data, df, on=\"ticker\", how=\"inner\")\n",
    "    return  data"
   ],
   "id": "777b1200c837bbf5",
   "outputs": [],
   "execution_count": 37
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-08T09:02:30.907731Z",
     "start_time": "2025-02-08T09:02:30.902977Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def optimize_dataframe(df: pd.DataFrame, metadata: list[dict]) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Optimize the dataframe column types based on provided metadata for efficient storage,\n",
    "    ensuring compatibility with Parquet format and DuckDB.\n",
    "\n",
    "    Args:\n",
    "        df (pd.DataFrame): The input dataframe.\n",
    "        metadata (list[dict]): List of column metadata with 'Column Name' and 'Type'.\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: Optimized dataframe.\n",
    "    \"\"\"\n",
    "    type_mapping = {\n",
    "        \"text\": \"category\",  # Use category for text as DuckDB treats it as enum\n",
    "        \"bool\": \"boolean\",  # Optimized for boolean storage\n",
    "        \"fundamental_price\": \"float64\",  # Higher precision for financial data\n",
    "        \"price\": \"float32\",  # Optimized float for prices\n",
    "        \"number\": \"float64\",  # Can store both int and float values efficiently\n",
    "        \"percent\": \"float32\",  # Percentage values stored as floats\n",
    "        \"num_slice\": \"object\",  # List of numbers, stored as object\n",
    "        \"time\": \"datetime64[ns]\",  # Timestamp format\n",
    "        \"interface\": \"object\",  # Keep JSON structures as object for DuckDB compatibility\n",
    "        \"time-yyyymmdd\": \"datetime64[ns]\",  # Date format optimized\n",
    "        \"set\": \"object\",  # Keep sets as object\n",
    "        \"map\": \"object\"  # Keep dictionary key-value pairs as object\n",
    "    }\n",
    "\n",
    "    for column in metadata:\n",
    "        col_name = column[\"Column Name\"]\n",
    "        col_type = column[\"Type\"].lower()\n",
    "\n",
    "        if col_name in df.columns:\n",
    "            mapped_type = type_mapping.get(col_type, \"object\")\n",
    "\n",
    "            if col_type == \"text\":\n",
    "                df[col_name] = df[col_name].astype(\"category\")  # Always use category for text\n",
    "            elif col_type == \"bool\":\n",
    "                df[col_name] = df[col_name].astype(mapped_type)\n",
    "            elif col_type in [\"fundamental_price\", \"number\", \"price\", \"percent\"]:\n",
    "                df[col_name] = pd.to_numeric(df[col_name], errors='coerce', downcast='float')\n",
    "            elif col_type == \"num_slice\":\n",
    "                df[col_name] = df[col_name].apply(lambda x: x if isinstance(x, list) else None)  # Use None instead of np.nan\n",
    "            elif col_type in [\"time\", \"time-yyyymmdd\"]:\n",
    "                date_format = '%Y%m%d' if col_type == \"time-yyyymmdd\" else None\n",
    "                df[col_name] = pd.to_datetime(df[col_name], format=date_format, errors='coerce')\n",
    "            elif col_type in [\"interface\", \"map\", \"set\"]:\n",
    "                pass  # Keep as object, no serialization\n",
    "            elif col_type == \"integer\":\n",
    "                df[col_name] = df[col_name].astype(pd.Int64Dtype())  # Nullable integer type\n",
    "            else:\n",
    "                df[col_name] = df[col_name].astype(mapped_type)\n",
    "\n",
    "    return df\n"
   ],
   "id": "d7e4f0ea012cd98d",
   "outputs": [],
   "execution_count": 38
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-08T09:02:32.129892Z",
     "start_time": "2025-02-08T09:02:31.713189Z"
    }
   },
   "cell_type": "code",
   "source": "columns = download_scanner_columns()",
   "id": "8c8359557f4ef8f8",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved scanner column info\n"
     ]
    }
   ],
   "execution_count": 39
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-08T08:37:53.300961Z",
     "start_time": "2025-02-08T08:37:53.297964Z"
    }
   },
   "cell_type": "code",
   "source": [
    "chunk_size = 50\n",
    "exclude_columns = ['index', 'index_id']\n",
    "filter_cols: list[str] = [c['Column Name'] for c in columns if c['Column Name'] not in exclude_columns]\n",
    "print(f\"Column filtered {len(filter_cols)}\")\n",
    "columns_chunks = [filter_cols[i:i + chunk_size] for i in range(0, len(filter_cols), chunk_size)]\n",
    "print(f\"Column chunk {len(columns_chunks)}\")"
   ],
   "id": "c53ba2be682cf670",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Column filtered 3342\n",
      "Column chunk 67\n"
     ]
    }
   ],
   "execution_count": 24
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-08T08:38:07.298385Z",
     "start_time": "2025-02-08T08:37:53.818058Z"
    }
   },
   "cell_type": "code",
   "source": "df:pd.DataFrame = download_scanner_data('india', columns_chunks[0:5])",
   "id": "4863d9b484250a4b",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 50\n",
      "Loaded 100\n",
      "Loaded 150\n",
      "Loaded 200\n",
      "Loaded 250\n"
     ]
    }
   ],
   "execution_count": 25
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-08T08:53:50.924967Z",
     "start_time": "2025-02-08T08:53:50.880157Z"
    }
   },
   "cell_type": "code",
   "source": "optimize_dataframe(df,metadata=columns).info()",
   "id": "f09792cff8c46c5",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 2773 entries, 0 to 2772\n",
      "Columns: 251 entries, ticker to CCI20|1\n",
      "dtypes: boolean(2), category(2), float32(142), float64(104), object(1)\n",
      "memory usage: 3.7+ MB\n"
     ]
    }
   ],
   "execution_count": 29
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-08T08:38:11.668993Z",
     "start_time": "2025-02-08T08:38:11.658437Z"
    }
   },
   "cell_type": "code",
   "source": "df.info()",
   "id": "386f3040cab34d3c",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 2773 entries, 0 to 2772\n",
      "Columns: 251 entries, ticker to CCI20|1\n",
      "dtypes: bool(2), float64(236), int64(10), object(3)\n",
      "memory usage: 5.3+ MB\n"
     ]
    }
   ],
   "execution_count": 26
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "e626a816b2f117c7"
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "language": "python",
   "display_name": "Python 3 (ipykernel)"
  }
 },
 "nbformat": 5,
 "nbformat_minor": 9
}
